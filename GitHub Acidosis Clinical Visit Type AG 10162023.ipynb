{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.cloud.bigquery\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.getenv(\"WORKSPACE_CDR\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Condition Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acidosis\n",
    "acidosis = {'9': ['276.2'], \n",
    "       '10': ['E87.2']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Cohort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Demographics Data from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket = 'demographic_all.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "demo_patients = pd.read_csv(name_of_file_in_bucket)\n",
    "demo_patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Patient List of Acidosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket = 'metformin_acidosis_AG_10132023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = my_dataframe['person_id'].tolist()\n",
    "person_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Query Visit Occurrence by Person_id from Acidosis Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Query person ids and condition start dates by specific ICD 9&10 diagnosis codes.\n",
    "def query_by_person():  \n",
    "    query = (\"\"\"\n",
    "                SELECT *\n",
    "                FROM \n",
    "                    `\"\"\"+dataset+\"\"\".ds_visit_occurrence` AS vo\n",
    "                WHERE\n",
    "                    vo.person_id IN (\"\"\"+\",\".join([str(pid) for pid in person_list])+\"\"\")\n",
    "    \"\"\")\n",
    "    df_condition= pd.read_gbq(query, dialect=\"standard\")\n",
    "    return df_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit = query_by_person()\n",
    "df_visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Dataset to Google Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = df_visit\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'Acidosis_Visit_Occurrence_AG_10162023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket = 'Acidosis_Visit_Occurrence_AG_10162023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = my_dataframe[['STANDARD_CONCEPT_NAME','STANDARD_CONCEPT_CODE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code lists objects in your Google Bucket\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_demo = df_visit.rename(columns={'person_id':\"Count\",\n",
    "                                            'year_of_birth':\"Age\",\n",
    "                                            'gender_source_value': \"Gender\",\n",
    "                                            'sex_at_birth_source_value':\"Sex at Birth\",\n",
    "                                            'race_source_value':\"Race\",\n",
    "                                            'ethnicity_source_value':\"Hispanic\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_demo.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_visit_gr = cleaned_demo[['PERSON_ID','STANDARD_CONCEPT_NAME']].groupby(['STANDARD_CONCEPT_NAME'], as_index=False).count()\n",
    "count_visit_gr['%'] = 100 * count_visit_gr['PERSON_ID'] / len(cleaned_demo)\n",
    "display(count_visit_gr)\n",
    "\n",
    "sns.barplot(x='PERSON_ID', y='STANDARD_CONCEPT_NAME',data=cleaned_demo[['PERSON_ID','STANDARD_CONCEPT_NAME']].groupby(['STANDARD_CONCEPT_NAME'], as_index=False).count());"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
