{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up + Find Condition Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and codes\n",
    "%load_ext google.cloud.bigquery\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import dateutil\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = os.getenv(\"WORKSPACE_CDR\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OMOP Codes for Medications\n",
    "\n",
    "# Metformin = 1503297\n",
    "medications = ['1503297']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_66101830_drug_sql = \"\"\"\n",
    "    SELECT\n",
    "        d_exposure.person_id,\n",
    "        d_exposure.drug_concept_id,\n",
    "        d_standard_concept.concept_name as standard_concept_name,\n",
    "        d_standard_concept.concept_code as standard_concept_code,\n",
    "        d_standard_concept.vocabulary_id as standard_vocabulary,\n",
    "        d_exposure.drug_exposure_start_datetime,\n",
    "        d_exposure.drug_exposure_end_datetime,\n",
    "        d_exposure.verbatim_end_date,\n",
    "        d_exposure.drug_type_concept_id,\n",
    "        d_type.concept_name as drug_type_concept_name,\n",
    "        d_exposure.stop_reason,\n",
    "        d_exposure.refills,\n",
    "        d_exposure.quantity,\n",
    "        d_exposure.days_supply,\n",
    "        d_exposure.sig,\n",
    "        d_exposure.route_concept_id,\n",
    "        d_route.concept_name as route_concept_name,\n",
    "        d_exposure.lot_number,\n",
    "        d_exposure.visit_occurrence_id,\n",
    "        d_visit.concept_name as visit_occurrence_concept_name,\n",
    "        d_exposure.drug_source_value,\n",
    "        d_exposure.drug_source_concept_id,\n",
    "        d_source_concept.concept_name as source_concept_name,\n",
    "        d_source_concept.concept_code as source_concept_code,\n",
    "        d_source_concept.vocabulary_id as source_vocabulary,\n",
    "        d_exposure.route_source_value,\n",
    "        d_exposure.dose_unit_source_value \n",
    "    FROM\n",
    "        ( SELECT\n",
    "            * \n",
    "        FROM\n",
    "            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".drug_exposure` d_exposure \n",
    "        WHERE\n",
    "            (\n",
    "                drug_concept_id IN  (\n",
    "                    SELECT\n",
    "                        DISTINCT ca.descendant_id \n",
    "                    FROM\n",
    "                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria_ancestor` ca \n",
    "                    JOIN\n",
    "                        (\n",
    "                            select\n",
    "                                distinct c.concept_id \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                            JOIN\n",
    "                                (\n",
    "                                    select\n",
    "                                        cast(cr.id as string) as id \n",
    "                                    FROM\n",
    "                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                    WHERE\n",
    "                                        concept_id IN (\"\"\"+\",\".join([str(cid) for cid in medications])+\"\"\")\n",
    "                                        AND full_text LIKE '%_rank1]%'\n",
    "                                ) a \n",
    "                                    ON (\n",
    "                                        c.path LIKE CONCAT('%.',\n",
    "                                    a.id,\n",
    "                                    '.%') \n",
    "                                    OR c.path LIKE CONCAT('%.',\n",
    "                                    a.id) \n",
    "                                    OR c.path LIKE CONCAT(a.id,\n",
    "                                    '.%') \n",
    "                                    OR c.path = a.id) \n",
    "                                WHERE\n",
    "                                    is_standard = 1 \n",
    "                                    AND is_selectable = 1\n",
    "                                ) b \n",
    "                                    ON (\n",
    "                                        ca.ancestor_id = b.concept_id\n",
    "                                    )\n",
    "                            )\n",
    "                        )  \n",
    "                        AND (\n",
    "                            d_exposure.PERSON_ID IN (\n",
    "                                SELECT\n",
    "                                    distinct person_id  \n",
    "                            FROM\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_person` cb_search_person  \n",
    "                            WHERE\n",
    "                                cb_search_person.person_id IN (\n",
    "                                    SELECT\n",
    "                                        criteria.person_id \n",
    "                                    FROM\n",
    "                                        (SELECT\n",
    "                                            DISTINCT person_id,\n",
    "                                            entry_date,\n",
    "                                            concept_id \n",
    "                                        FROM\n",
    "                                            `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_search_all_events` \n",
    "                                        WHERE\n",
    "                                            (\n",
    "                                                concept_id IN (\n",
    "                                                    SELECT\n",
    "                                                        DISTINCT ca.descendant_id \n",
    "                                                    FROM\n",
    "                                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria_ancestor` ca \n",
    "                                                    JOIN\n",
    "                                                        (\n",
    "                                                            select\n",
    "                                                                distinct c.concept_id \n",
    "                                                            FROM\n",
    "                                                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` c \n",
    "                                                            JOIN\n",
    "                                                                (\n",
    "                                                                    select\n",
    "                                                                        cast(cr.id as string) as id \n",
    "                                                                    FROM\n",
    "                                                                        `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".cb_criteria` cr \n",
    "                                                                    WHERE\n",
    "                                                                        concept_id IN (\"\"\"+\",\".join([str(cid) for cid in medications])+\"\"\") \n",
    "                                                                        AND full_text LIKE '%_rank1]%'\n",
    "                                                                ) a \n",
    "                                                                    ON (\n",
    "                                                                        c.path LIKE CONCAT('%.',\n",
    "                                                                    a.id,\n",
    "                                                                    '.%') \n",
    "                                                                    OR c.path LIKE CONCAT('%.',\n",
    "                                                                    a.id) \n",
    "                                                                    OR c.path LIKE CONCAT(a.id,\n",
    "                                                                    '.%') \n",
    "                                                                    OR c.path = a.id) \n",
    "                                                                WHERE\n",
    "                                                                    is_standard = 1 \n",
    "                                                                    AND is_selectable = 1\n",
    "                                                                ) b \n",
    "                                                                    ON (\n",
    "                                                                        ca.ancestor_id = b.concept_id\n",
    "                                                                    )\n",
    "                                                            ) \n",
    "                                                            AND is_standard = 1\n",
    "                                                        )\n",
    "                                                ) criteria \n",
    "                                            ) \n",
    "                                        ))) d_exposure \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_standard_concept \n",
    "                                    ON d_exposure.drug_concept_id = d_standard_concept.concept_id \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_type \n",
    "                                    ON d_exposure.drug_type_concept_id = d_type.concept_id \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_route \n",
    "                                    ON d_exposure.route_concept_id = d_route.concept_id \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".visit_occurrence` v \n",
    "                                    ON d_exposure.visit_occurrence_id = v.visit_occurrence_id \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_visit \n",
    "                                    ON v.visit_concept_id = d_visit.concept_id \n",
    "                            LEFT JOIN\n",
    "                                `\"\"\" + os.environ[\"WORKSPACE_CDR\"] + \"\"\".concept` d_source_concept \n",
    "                                    ON d_exposure.drug_source_concept_id = d_source_concept.concept_id\"\"\"\n",
    "\n",
    "dataset_66101830_drug_df = pd.read_gbq(\n",
    "    dataset_66101830_drug_sql,\n",
    "    dialect=\"standard\",\n",
    "    use_bqstorage_api=(\"BIGQUERY_STORAGE_API_ENABLED\" in os.environ),\n",
    "    progress_bar_type=\"tqdm_notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_66101830_drug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many duplicates there are\n",
    "dataset_66101830_drug_df[dataset_66101830_drug_df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates\n",
    "metformin_med = dataset_66101830_drug_df.drop_duplicates()\n",
    "metformin_med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how many unique patients are in the dataset\n",
    "metformin_med['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = metformin_med   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'Metformin_Medication_AG_10122023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each drug in the dataset\n",
    "dataset_66101830_drug_df['standard_concept_name'].sort_values(ascending=True).value_counts().head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload the whole dataset as parquet file to Google Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = dataset_66101830_drug_df   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'Metformin_Cases_AG_10122023.parquet.gzip'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a parquet file in the same workspace as the notebook\n",
    "my_dataframe.to_parquet(destination_filename, compression='gzip')\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy parquet file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload metformin dataframe\n",
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket = 'Metformin_Medication_AG_10122023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "my_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of unique PIDs\n",
    "my_dataframe['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort unique person ids by their earliset condition date.\n",
    "def sort_unique_by_min_date(df): \n",
    "    min_dates_diags = df.sort_values([\"person_id\",\"drug_exposure_start_datetime\"]).groupby(\"person_id\", as_index=False).first()\n",
    "    return min_dates_diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dates_diags = sort_unique_by_min_date(my_dataframe)\n",
    "min_dates_diags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv file (min date)\n",
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = min_dates_diags   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'Metformin_Medication_Min_Date_AG_10122023.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code lists objects in your Google Bucket\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe['person_id'].duplicated(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = my_dataframe.drop_duplicates('person_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = my_df.reset_index(drop=True)\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df['person_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_list = my_df['person_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload demo data\n",
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "name_of_file_in_bucket = 'demographic_all.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file from the bucket to the current working space\n",
    "os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "demo = pd.read_csv(name_of_file_in_bucket)\n",
    "demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = demo[demo['person_id'].isin(person_list)]\n",
    "demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = demo.reset_index()\n",
    "\n",
    "cleaned_demo = demo[['person_id','year_of_birth','gender_source_value','sex_at_birth_source_value','race_source_value', 'ethnicity_source_value']]\n",
    "\n",
    "\n",
    "cleaned_demo = cleaned_demo.rename(columns={'person_id':\"Count\",\n",
    "                                            'year_of_birth':\"Age\",\n",
    "                                            'gender_source_value': \"Gender\",\n",
    "                                            'sex_at_birth_source_value':\"Sex at Birth\",\n",
    "                                            'race_source_value':\"Race\",\n",
    "                                            'ethnicity_source_value':\"Hispanic\"})\n",
    "\n",
    "\n",
    "for row in (range(cleaned_demo.shape[0])):\n",
    "    for col in (range(cleaned_demo.shape[1])):\n",
    "        if cleaned_demo.iloc[row,col] == \"PMI_Skip\":\n",
    "            cleaned_demo.iloc[row,col] = \"Skip\"\n",
    "        if cleaned_demo.iloc[row,col] in [\"PMI_PreferNotToAnswer\",\n",
    "                                          \"SexAtBirth_Intersex\",\n",
    "                                          \"SexAtBirth_SexAtBirthNoneOfThese\",\n",
    "                                          \"No matching concept\",\n",
    "                                          \"GenderIdentity_AdditionalOptions\",\n",
    "                                          \"GenderIdentity_GeneralizedDiffGender\",\n",
    "                                          \"GenderIdentity_NonBinary\",\n",
    "                                          \"GenderIdentity_Transgender\"]:\n",
    "            cleaned_demo.iloc[row,col] = \"Unspecified\"\n",
    "\n",
    "\n",
    "for x in range(len(cleaned_demo)):\n",
    "    birth_year = cleaned_demo.at[x,'Age']\n",
    "    cleaned_demo.at[x,'Age'] = date.today().year - birth_year\n",
    "\n",
    "bins = [0,29,49,69,89,1000]\n",
    "labels = ['0-29','30-49','50-69','70-89','90+']\n",
    "cleaned_demo['Age Group'] = pd.cut(cleaned_demo['Age'], bins=bins, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summarization and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sex at Birth & Gender Identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_gender_gr = cleaned_demo[['Count','Gender']].groupby(['Gender'], as_index=False).count()\n",
    "count_gender_gr['%'] = 100 * count_gender_gr['Count'] / len(cleaned_demo)\n",
    "display(count_gender_gr)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(cleaned_demo['Gender'].value_counts(), labels=['GenderIdentity_Woman','GenderIdentity_Man','Unspecified','Skip'], \n",
    "        autopct='%1.1f%%', startangle=90, pctdistance=0.5)\n",
    "ax1.axis('equal')\n",
    "fig = plt.gcf().gca().add_artist(plt.Circle((0,0),0.70,fc='white'))\n",
    "plt.tight_layout()\n",
    "#rcParams['figure.figsize'] = (10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Race and Ancestry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_race_gr = cleaned_demo[['Count','Race']].groupby(['Race'], as_index=False).count()\n",
    "count_race_gr['%'] = 100 * count_race_gr['Count'] / len(cleaned_demo)\n",
    "display(count_race_gr)\n",
    "\n",
    "sns.barplot(x='Count', y='Race',data=cleaned_demo[['Count','Race']].groupby(['Race'], as_index=False).count());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_eth_gr = cleaned_demo[['Count','Hispanic']].groupby(['Hispanic'], as_index=False).count()\n",
    "count_eth_gr['%'] = 100 * count_eth_gr['Count'] / len(cleaned_demo)\n",
    "display(count_eth_gr)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(cleaned_demo['Hispanic'].value_counts(),  #labels=['Not HLS','Hispanic, Latino, or Spanish', 'Skip', 'None of These', 'Prefer not to Answer'],\n",
    "        autopct='%1.1f%%', startangle=0, pctdistance=0.5)\n",
    "ax1.axis('equal')\n",
    "fig = plt.gcf().gca().add_artist(plt.Circle((0,0),0.70,fc='white'))\n",
    "plt.tight_layout()\n",
    "#rcParams['figure.figsize'] = (10,10)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_age_gr = cleaned_demo[['Count','Age Group']].groupby(['Age Group'], as_index=False).count()\n",
    "count_age_gr['%'] = 100 * count_age_gr['Count'] / len(cleaned_demo)\n",
    "display(count_age_gr)\n",
    "\n",
    "\n",
    "#rcParams['figure.figsize'] = (20,10)\n",
    "sns.histplot(cleaned_demo['Age']);\n",
    "\n",
    "summary = cleaned_demo.groupby('Age Group')['Age'].describe()[['min', '25%', '50%', '75%', 'max']]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = cleaned_demo.groupby(['Age']).size()\n",
    "pd.set_option('display.max_rows', None)\n",
    "print(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(cleaned_demo['Age'], bins=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
